{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from  torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(1,1, kernel_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(conv.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_params = list(conv.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.3925]]]], requires_grad=True), Parameter containing:\n",
       " tensor([0.9319], requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight', Parameter containing:\n",
       "  tensor([[[[-0.3925]]]], requires_grad=True)), ('bias', Parameter containing:\n",
       "  tensor([0.9319], requires_grad=True))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,1, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(1,1, kernel_size=3)\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(1,1, kernel_size=3),\n",
    "            nn.Conv2d(1,1, kernel_size=3),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(1,1, kernel_size=3),\n",
    "            nn.Conv2d(1,1, kernel_size=3),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        return x\n",
    "    \n",
    "model = TestNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mparam = list(model.parameters())\n",
    "nparam = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[ 0.2056,  0.2884,  0.0164],\n",
       "           [-0.1758,  0.0430,  0.1899],\n",
       "           [-0.1654,  0.0868, -0.2053]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1598], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.2011, -0.2741,  0.1188],\n",
       "           [-0.1493, -0.1230, -0.2897],\n",
       "           [-0.0751,  0.1814,  0.1577]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0479], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0548, -0.0474, -0.0260],\n",
       "           [-0.2184,  0.0244,  0.1152],\n",
       "           [ 0.0044, -0.1206, -0.3273]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0608], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0322,  0.0542,  0.1376],\n",
       "           [ 0.2496, -0.1909, -0.0437],\n",
       "           [-0.2114, -0.2389,  0.1166]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1664], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0519,  0.0189,  0.1214],\n",
       "           [ 0.2483,  0.1822, -0.0169],\n",
       "           [-0.0503,  0.1324,  0.2998]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2438], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0262, -0.1962,  0.2279],\n",
       "           [-0.1180, -0.2732, -0.2529],\n",
       "           [ 0.0203,  0.0783, -0.2501]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3134], requires_grad=True)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "conv1.bias\n",
      "conv2.weight\n",
      "conv2.bias\n",
      "conv_block1.0.weight\n",
      "conv_block1.0.bias\n",
      "conv_block1.1.weight\n",
      "conv_block1.1.bias\n",
      "conv_block2.0.weight\n",
      "conv_block2.0.bias\n",
      "conv_block2.1.weight\n",
      "conv_block2.1.bias\n"
     ]
    }
   ],
   "source": [
    "key = []\n",
    "for p in nparam:\n",
    "    print(p[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.SGD([\n",
    "    {'params':model.conv1.parameters(), 'lr':0.001},\n",
    "    {'params':model.conv2.parameters(), 'lr':0.001},\n",
    "    \n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(name_split):\n",
    "    if len(name_split)<=2:\n",
    "        key = name_split[-2]\n",
    "    else:\n",
    "        key = '.'.join(name_split[:-1]) \n",
    "    return key\n",
    "\n",
    "def print_named_params(model):\n",
    "    named_params = model.named_parameters()\n",
    "    layer_group = collections.OrderedDict()\n",
    "    pair_group = {}\n",
    "    param_group = []\n",
    "    last_name = \"\"\n",
    "    result = None\n",
    "    for idx, (name, param) in enumerate(named_params):\n",
    "        name_split = name.split(\".\")\n",
    "        layer_name, name_type = name_split[-2], name_split[-1]          \n",
    "        usable_name = f'{layer_name}.{name_type}'\n",
    "        key = get_name(name_split)\n",
    "#         print(name)\n",
    "        if idx==0:\n",
    "            param_group.append((usable_name, ''))\n",
    "            layer_group[key] = param_group\n",
    "            last_name = layer_name\n",
    "        else:\n",
    "            if last_name == layer_name:\n",
    "                pair_group[usable_name] = ''\n",
    "                param_group.append((usable_name,''))\n",
    "                layer_group[key] = param_group\n",
    "            else:\n",
    "                param_group = []\n",
    "                param_group.append((usable_name,''))\n",
    "                layer_group[key] = param_group\n",
    "        last_name = layer_name\n",
    "    result = layer_group\n",
    "    return result\n",
    "\n",
    "def create_param_group(model):\n",
    "    named_params = model.named_parameters()\n",
    "    layer_group = collections.OrderedDict()\n",
    "    pair_group = {}\n",
    "    param_group = []\n",
    "    last_name = \"\"\n",
    "    result = None\n",
    "    for idx, (name, param) in enumerate(named_params):\n",
    "        name_split = name.split(\".\")\n",
    "        layer_name, name_type = name_split[-2], name_split[-1]          \n",
    "        usable_name = f'{layer_name}.{name_type}'\n",
    "        key = get_name(name_split)\n",
    "#         print(name)\n",
    "        if idx==0:\n",
    "#             param_group.append((usable_name, 'param'))\n",
    "            param_group.append(param)\n",
    "            layer_group[key] = param_group\n",
    "            last_name = layer_name\n",
    "        else:\n",
    "            if last_name == layer_name:\n",
    "#                 param_group.append((usable_name,'param'))\n",
    "                param_group.append(param)\n",
    "                layer_group[key] = param_group\n",
    "            else:\n",
    "                param_group = []\n",
    "#                 param_group.append((usable_name,'param'))\n",
    "                param_group.append(param)\n",
    "                layer_group[key] = param_group\n",
    "        last_name = layer_name\n",
    "    result = layer_group\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9f7e6cb28ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparam_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e6a12afbd0e9>\u001b[0m in \u001b[0;36mcreate_param_group\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mnamed_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mlayer_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mpair_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mparam_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collections' is not defined"
     ]
    }
   ],
   "source": [
    "test_model = models.resnet18()\n",
    "param_group = create_param_group(test_model)\n",
    "for k,v in param_group.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight conv1\n",
      "bn1.weight bn1\n",
      "bn1.bias bn1\n",
      "layer1.0.conv1.weight layer1.0.conv1\n",
      "layer1.0.bn1.weight layer1.0.bn1\n",
      "layer1.0.bn1.bias layer1.0.bn1\n",
      "layer1.0.conv2.weight layer1.0.conv2\n",
      "layer1.0.bn2.weight layer1.0.bn2\n",
      "layer1.0.bn2.bias layer1.0.bn2\n",
      "layer1.1.conv1.weight layer1.1.conv1\n",
      "layer1.1.bn1.weight layer1.1.bn1\n",
      "layer1.1.bn1.bias layer1.1.bn1\n",
      "layer1.1.conv2.weight layer1.1.conv2\n",
      "layer1.1.bn2.weight layer1.1.bn2\n",
      "layer1.1.bn2.bias layer1.1.bn2\n",
      "layer2.0.conv1.weight layer2.0.conv1\n",
      "layer2.0.bn1.weight layer2.0.bn1\n",
      "layer2.0.bn1.bias layer2.0.bn1\n",
      "layer2.0.conv2.weight layer2.0.conv2\n",
      "layer2.0.bn2.weight layer2.0.bn2\n",
      "layer2.0.bn2.bias layer2.0.bn2\n",
      "layer2.0.downsample.0.weight layer2.0.downsample.0\n",
      "layer2.0.downsample.1.weight layer2.0.downsample.1\n",
      "layer2.0.downsample.1.bias layer2.0.downsample.1\n",
      "layer2.1.conv1.weight layer2.1.conv1\n",
      "layer2.1.bn1.weight layer2.1.bn1\n",
      "layer2.1.bn1.bias layer2.1.bn1\n",
      "layer2.1.conv2.weight layer2.1.conv2\n",
      "layer2.1.bn2.weight layer2.1.bn2\n",
      "layer2.1.bn2.bias layer2.1.bn2\n",
      "layer3.0.conv1.weight layer3.0.conv1\n",
      "layer3.0.bn1.weight layer3.0.bn1\n",
      "layer3.0.bn1.bias layer3.0.bn1\n",
      "layer3.0.conv2.weight layer3.0.conv2\n",
      "layer3.0.bn2.weight layer3.0.bn2\n",
      "layer3.0.bn2.bias layer3.0.bn2\n",
      "layer3.0.downsample.0.weight layer3.0.downsample.0\n",
      "layer3.0.downsample.1.weight layer3.0.downsample.1\n",
      "layer3.0.downsample.1.bias layer3.0.downsample.1\n",
      "layer3.1.conv1.weight layer3.1.conv1\n",
      "layer3.1.bn1.weight layer3.1.bn1\n",
      "layer3.1.bn1.bias layer3.1.bn1\n",
      "layer3.1.conv2.weight layer3.1.conv2\n",
      "layer3.1.bn2.weight layer3.1.bn2\n",
      "layer3.1.bn2.bias layer3.1.bn2\n",
      "layer4.0.conv1.weight layer4.0.conv1\n",
      "layer4.0.bn1.weight layer4.0.bn1\n",
      "layer4.0.bn1.bias layer4.0.bn1\n",
      "layer4.0.conv2.weight layer4.0.conv2\n",
      "layer4.0.bn2.weight layer4.0.bn2\n",
      "layer4.0.bn2.bias layer4.0.bn2\n",
      "layer4.0.downsample.0.weight layer4.0.downsample.0\n",
      "layer4.0.downsample.1.weight layer4.0.downsample.1\n",
      "layer4.0.downsample.1.bias layer4.0.downsample.1\n",
      "layer4.1.conv1.weight layer4.1.conv1\n",
      "layer4.1.bn1.weight layer4.1.bn1\n",
      "layer4.1.bn1.bias layer4.1.bn1\n",
      "layer4.1.conv2.weight layer4.1.conv2\n",
      "layer4.1.bn2.weight layer4.1.bn2\n",
      "layer4.1.bn2.bias layer4.1.bn2\n",
      "fc.weight fc\n",
      "fc.bias fc\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def test_param_group(test_model):\n",
    "    param_group = create_param_group(test_model)\n",
    "    parameters = list(test_model.parameters())\n",
    "    named_parameters = list(test_model.named_parameters())\n",
    "    \n",
    "    idx = 0\n",
    "    for key, values in param_group.items():\n",
    "        for value in values:\n",
    "            if value is parameters[idx]:\n",
    "                print(named_parameters[idx][0], key)\n",
    "            idx = idx+1\n",
    "    print(idx == len(named_parameters))\n",
    "test_param_group(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_group['layer1.0.conv1'][0] is list(test_model.parameters())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for c in list(test_model.children()):\n",
    "#     print(c)\n",
    "#     try:\n",
    "#         cc = c.children()\n",
    "#         print(list(cc))\n",
    "#     except:\n",
    "#         pass\n",
    "#     print()\n",
    "    \n",
    "def flatten_model(model):\n",
    "    module = []\n",
    "    for mod in list(model.children()):\n",
    "        if has_child(mod):\n",
    "            \n",
    "        sub = list(mod.children())\n",
    "        if len(sub)>0:\n",
    "#             flatten_model(mod)\n",
    "            print(sub)\n",
    "        else:\n",
    "            print('no children')\n",
    "            module.append(mod)\n",
    "            \n",
    "    return module\n",
    "                \n",
    "       \n",
    "        \n",
    "                \n",
    "\n",
    "def has_child(mod):\n",
    "    try:\n",
    "        sub = list(mod.children())\n",
    "        if len(sub)>0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "mod = list(test_model.children())\n",
    "has_child(mod[0])\n",
    "    \n",
    "# flatten_model(test_model)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResNet(\n",
       "   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       " ),\n",
       " Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Sequential(\n",
       "   (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Sequential(\n",
       "   (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Sequential(\n",
       "   (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "   (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
       " BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " BasicBlock(\n",
       "   (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace)\n",
       "   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace),\n",
       " Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_model.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParser:\n",
    "    @staticmethod\n",
    "    def get_name(name_split):\n",
    "        if len(name_split)<=2:\n",
    "            key = name_split[-2]\n",
    "        else:\n",
    "            key = '.'.join(name_split[:-1])\n",
    "        return key\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params_group(model):\n",
    "        layer_group = collections.OrderedDict()\n",
    "        param_group, last_name = [], \"\"\n",
    "        for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "            name_split = name.split(\".\")\n",
    "            layer_name, name_type = name_split[-2], name_split[-1]\n",
    "            key = ModelParser.get_name(name_split)\n",
    "            if idx == 0:\n",
    "                param_group.append(param)\n",
    "                layer_group[key] = param_group\n",
    "                last_name = layer_name\n",
    "            else:\n",
    "                if last_name == layer_name:\n",
    "                    param_group.append(param)\n",
    "                    layer_group[key] = param_group\n",
    "                else:\n",
    "                    param_group = []\n",
    "                    param_group.append(param)\n",
    "                    layer_group[key] = param_group\n",
    "            last_name = layer_name\n",
    "        return layer_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8fe48cc31cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mModelParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_model' is not defined"
     ]
    }
   ],
   "source": [
    "ModelParser.get_params_group(test_model).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 2\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 3\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 4\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 5\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 6\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 7\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.1\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import *\n",
    "import collections\n",
    "class OptimizerWrapper(object):\n",
    "    def __init__(self, model: nn.Module, optimizer:optim.Optimizer = None):\n",
    "        self.model = model\n",
    "        self.optimizer: optim.Optimizer = optimizer\n",
    "    \n",
    "    def create(self, lr: Union[float, list], name='sgd', **kwargs):\n",
    "        model_params = self._model_parameters(lr)\n",
    "        if self.optimizer:\n",
    "            return self.optimizer(model_params)\n",
    "        else:\n",
    "            self.optimizer = optim.Adam\n",
    "            return self.optimizer(model_params)\n",
    "        \n",
    "        \n",
    "    def _model_parameters(self, lr:Union[float, list], **kwargs):\n",
    "        parameters = self._model_param_group()\n",
    "        if type(lr) == list:\n",
    "            build = []\n",
    "            lr_len = len(lr)\n",
    "            param_len = len(parameters)\n",
    "            lr_every = None\n",
    "            if param_len < lr_len:\n",
    "                raise ValueError('lr list is more bigger than model parameter, try to remove item on list!')\n",
    "            else:\n",
    "                 lr_every = param_len // len(lr)\n",
    "            \n",
    "            lr_idx = 0\n",
    "            for idx, param in enumerate(parameters):   \n",
    "                if idx % lr_every == 0 and idx!=0:\n",
    "                    lr_idx+=1\n",
    "                if len(lr)<=lr_idx:\n",
    "                    lr_idx-=1\n",
    "#                 print(idx, lr[lr_idx])\n",
    "                par = {'params': param, 'lr':lr[lr_idx]}\n",
    "                build.append(par)\n",
    "            return build\n",
    "        else:\n",
    "            return parameters\n",
    "            \n",
    "    \n",
    "    def _lr_every(self,param, lr):\n",
    "        param_len = len(param)\n",
    "        lr_every = param_len // len(lr)\n",
    "        lr_list = []\n",
    "        for idx in range(param_len):\n",
    "            if  idx % lr_every == 0 and id!=0:\n",
    "                lr_list.append(idx)\n",
    "        return lr_list\n",
    "\n",
    "    \n",
    "    def _model_param_group_odict(self):\n",
    "        return ModelParser.get_params_group(self.model)\n",
    "    \n",
    "    def _model_param_group(self):\n",
    "        parameters = []\n",
    "        for idx, (name, param) in enumerate(self._model_param_group_odict().items()):\n",
    "            parameters.append(param)\n",
    "        return parameters\n",
    "    \n",
    "    \n",
    "\n",
    "test_model = models.alexnet()\n",
    "opt = optim.Adam        \n",
    "optwr = OptimizerWrapper(test_model)\n",
    "optwr.create(lr=[0.1], betas=[0.5,0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "a = optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.1\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd(test_model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [idx for idx in range(param_len)]\n",
    "\n",
    "def get_lr_every(param, lr):\n",
    "    param_len = len(param)\n",
    "    lr_len = len(lr)\n",
    "    lr_every = param_len // lr_len\n",
    "    lr_list = []\n",
    "    for idx in range(param_len):\n",
    "        if  idx % lr_every == 0 and idx!=0:\n",
    "            lr_list.append(idx)\n",
    "    return lr_list[:-1]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "every = 8\n",
    "c = 0 \n",
    "for i in range(1,10):\n",
    "    if i % every == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
